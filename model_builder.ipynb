{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = []\n",
    "all_files = glob.glob(os.path.join('blogfeedback', '*.csv'))\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "    test_sets.append(df)\n",
    "\n",
    "train_data = pd.read_csv('blogData_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1...50: \n",
    "#       Average, standard deviation, min, max and median of the \n",
    "#       Attributes 51...60 for the source of the current blog post\n",
    "#       With source we mean the blog on which the post appeared. \n",
    "#       For example, myblog.blog.org would be the source of \n",
    "#       the post myblog.blog.org/post_2010_09_10 \n",
    "# 51:   Total number of comments before basetime\n",
    "# 52:   Number of comments in the last 24 hours before the \n",
    "#       basetime\n",
    "# 53:   Let T1 denote the datetime 48 hours before basetime,\n",
    "#       Let T2 denote the datetime 24 hours before basetime.\n",
    "#       This attribute is the number of comments in the time period \n",
    "#       between T1 and T2\n",
    "# 54:   Number of comments in the first 24 hours after the \n",
    "#       publication of the blog post, but before basetime\n",
    "# 55:   The difference of Attribute 52 and Attribute 53\n",
    "# 56...60: \n",
    "#       The same features as the attributes 51...55, but  \n",
    "#       features 56...60 refer to the number of links (trackbacks), \n",
    "#       while features 51...55 refer to the number of comments.\n",
    "# 61:   The length of time between the publication of the blog post \n",
    "#       and basetime\n",
    "# 62:   The length of the blog post\n",
    "# 63...262: \n",
    "#       The 200 bag of words features for 200 frequent words of the \n",
    "#       text of the blog post\n",
    "# 263...269: binary indicator features (0 or 1) for the weekday\n",
    "#       (Monday...Sunday) of the basetime\n",
    "# 270...276: binary indicator features (0 or 1) for the weekday\n",
    "#       (Monday...Sunday) of the date of publication of the blog\n",
    "#       post\n",
    "# 277:  Number of parent pages: we consider a blog post P as a\n",
    "#       parent of blog post B, if B is a reply (trackback) to \n",
    "#       blog post P.\n",
    "# 278...280:  \n",
    "#       Minimum, maximum, average number of comments that the \n",
    "#       parents received\n",
    "# 281:  The target: the number of comments in the next 24 hours\n",
    "#       (relative to basetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_normalise = train_data.columns[50:60].append(train_data.columns[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_stats(df):\n",
    "\n",
    "    target_means = df.groupby(list(df.columns[:50]))[['target']].mean()\n",
    "    target_stdev = df.groupby(list(df.columns[:50]))[['target']].std()\n",
    "\n",
    "    df = pd.merge(df, target_means, how = \"left\", left_on = list(df.columns[:50]), right_on= list(df.columns[:50])).rename(columns={\"target_x\": \"target\", \"target_y\" : \"target_avg\"})\n",
    "    df = pd.merge(df, target_stdev, how = \"left\", left_on = list(df.columns[:50]), right_on= list(df.columns[:50])).rename(columns={\"target_x\": \"target\", \"target_y\" : \"target_stdev\"})\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def normalise_features(features, df):\n",
    "\n",
    "    normalised_df = df.assign(**{\n",
    "        feat + '_in_site_stdevs': np.where(\n",
    "            df[feat + '_stdev'] == 0, 0,\n",
    "            (df[feat] - df[feat + '_avg']) / df[feat + '_stdev']\n",
    "        )\n",
    "        for feat in features_to_normalise\n",
    "    })\n",
    "\n",
    "    return normalised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = find_target_stats(train_data)\n",
    "normalised_df = normalise_features(features_to_normalise, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = normalised_df[['target_in_site_stdevs']]\n",
    "\n",
    "all_feature_names = list(normalised_df.columns[0:280])\n",
    "all_features = normalised_df[all_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeRegressor(max_depth=100).fit(all_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = tree_model.feature_importances_\n",
    "\n",
    "imp_threshold = 0.0001\n",
    "selected_names = []\n",
    "\n",
    "idx = 0\n",
    "for imp_value in feature_importances:\n",
    "    if imp_value >= imp_threshold:\n",
    "        selected_names.append(all_features.columns[idx])\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = normalised_df[selected_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(fit_intercept=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(selected_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14489533801176524,\n",
       " -0.21981286005189937,\n",
       " 0.06096158790265349,\n",
       " -0.13869174003220097,\n",
       " -0.012397359323764734,\n",
       " -0.02694332469849936,\n",
       " -0.022003685350096447,\n",
       " 0.026643228796562002,\n",
       " 0.06864840667470562,\n",
       " 0.0548814227469282,\n",
       " -0.22952689859765796,\n",
       " 0.12672787124937113,\n",
       " -0.04261238183584792,\n",
       " 0.11727289275139008,\n",
       " 0.170224335905377,\n",
       " -0.11494777839264891,\n",
       " -0.029585457489375244,\n",
       " -0.02987092106621181,\n",
       " 0.14678308175102717,\n",
       " 0.02545689012025365,\n",
       " -0.28577523985720754,\n",
       " -0.007672961032793024,\n",
       " 0.14589010030103733,\n",
       " 0.045223501749205086,\n",
       " 0.009443466450714366,\n",
       " 0.04901977732749607,\n",
       " 0.0874022061144979,\n",
       " 0.20816499420943568,\n",
       " -0.10180705342716379,\n",
       " -0.1900787358445275,\n",
       " 0.07726232786996101,\n",
       " 0.05156246316645119,\n",
       " 0.06250462829181402,\n",
       " 0.08008374610855573,\n",
       " 0.24703026699099406,\n",
       " 0.07772116561526854,\n",
       " 0.15152977161315573,\n",
       " 0.16213042536856204,\n",
       " -0.19339250056029478,\n",
       " -0.011289243444313257,\n",
       " -0.1853119475158247,\n",
       " -0.4317446992555849,\n",
       " -0.005488947690429624,\n",
       " -0.12984625265181338,\n",
       " 0.009696351866591457,\n",
       " -0.07601701652784598,\n",
       " 0.18035836996118204,\n",
       " -0.026922794816001128,\n",
       " 0.08201020068031595,\n",
       " 0.11111812023680867,\n",
       " -0.3106757909327502,\n",
       " 0.11500788164660003,\n",
       " 0.06907508294685205,\n",
       " 0.002301733027592734,\n",
       " -0.02557791883038152,\n",
       " -0.08302092011070439,\n",
       " -0.2757213659199431,\n",
       " -5.6113988724737496e-05,\n",
       " -0.1745539807718981,\n",
       " -0.034002778163066294]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for _set in test_sets:\n",
    "    _set = find_target_stats(_set)\n",
    "    normalised_set = normalise_features(features_to_normalise, _set)\n",
    "    \n",
    "    features = normalised_set[selected_names]\n",
    "    labels = normalised_set[['target_in_site_stdevs']]\n",
    "\n",
    "    scores.append(model.score(features, labels))\n",
    "\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
